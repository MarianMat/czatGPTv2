import streamlit as st
from openai import OpenAI
import json
from pathlib import Path
from qdrant_utils import init_qdrant, save_to_qdrant

# üîë Inicjalizacja klienta OpenAI
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
qdrant_client = init_qdrant()

model_pricings = {
    "gpt-4o": {"Opis": "Multimodalny ‚Äì tekst, obraz, g≈Ços", "Input": 2.5, "Output": 10.0},
    "gpt-4o-mini": {"Opis": "Lekki i tani do chatbot√≥w", "Input": 0.15, "Output": 0.6},
    "gpt-4-turbo": {"Opis": "Szybki tekstowy model", "Input": 1.5, "Output": 6.0},
    "gpt-3.5-turbo": {"Opis": "Bud≈ºetowa opcja", "Input": 0.5, "Output": 1.5}
}
USD_TO_PLN = 3.97

translations = {
    "Polski": {
        "title": "üß† M√≥jGPT ‚Äì Inteligentny czat z pamiƒôciƒÖ",
        "chat_title": "üí¨ Rozmowa",
        "input_placeholder": "Zadaj pytanie",
        "language_switch": "üåç Jƒôzyk interfejsu",
        "conversation_list": "üìÇ Wybierz rozmowƒô",
        "new_conversation": "üîÑ Nowa rozmowa",
        "default_conversation_name": "Rozmowa {}",
        "model_select": "ü§ñ Wybierz model GPT",
        "personality": "üé≠ Styl GPT",
        "memory_mode": "üß† Tryb pamiƒôci",
        "export_button": "üì§ Eksportuj rozmowƒô",
        "download_txt": "‚¨áÔ∏è Pobierz jako TXT",
        "cost_usd": "üí∞ Koszt (USD)",
        "cost_pln": "üí∞ Koszt (PLN)",
        "default_personality": "Jeste≈õ ekspertem AI, kt√≥ry pomaga tworzyƒá projekty w Pythonie z wykorzystaniem API OpenAI (GPT, Whisper, DALL¬∑E itp.). Doradzasz w projektowaniu architektury, pisaniu kodu, integracjach oraz debugowaniu. Twoje odpowiedzi sƒÖ rzeczowe, praktyczne i dostosowane do poziomu u≈ºytkownika. Pomagasz szybko i skutecznie budowaƒá aplikacje AI oparte na API."
    },
    "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞": {
        "title": "üß† –ú—ñ–πGPT ‚Äì –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π —á–∞—Ç –∑ –ø–∞–º º—è—Ç—Ç—é",
        "chat_title": "üí¨ –ë–µ—Å—ñ–¥–∞",
        "input_placeholder": "–ó–∞–¥–∞–π –∑–∞–ø–∏—Ç–∞–Ω–Ω—è",
        "language_switch": "üåç –ú–æ–≤–∞ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É",
        "conversation_list": "üìÇ –í–∏–±–µ—Ä—ñ—Ç—å –±–µ—Å—ñ–¥—É",
        "new_conversation": "üîÑ –ù–æ–≤–∞ –±–µ—Å—ñ–¥–∞",
        "default_conversation_name": "–ë–µ—Å—ñ–¥–∞ {}",
        "model_select": "ü§ñ –í–∏–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å GPT",
        "personality": "üé≠ –°—Ç–∏–ª—å GPT",
        "memory_mode": "üß† –†–µ–∂–∏–º –ø–∞–º º—è—Ç—ñ",
        "export_button": "üì§ –ï–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –±–µ—Å—ñ–¥—É",
        "download_txt": "‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —è–∫ TXT",
        "cost_usd": "üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å (USD)",
        "cost_pln": "üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å (PLN)",
        "default_personality": "–¢–∏ —î –µ–∫—Å–ø–µ—Ä—Ç–æ–º –∑ —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É, —è–∫–∏–π –¥–æ–ø–æ–º–∞–≥–∞—î —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –ø—Ä–æ—î–∫—Ç–∏ –Ω–∞ Python –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º API OpenAI (GPT, Whisper, DALL¬∑E —Ç–æ—â–æ). –¢–∏ –Ω–∞–¥–∞—î—à –ø–æ—Ä–∞–¥–∏ —â–æ–¥–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏, –Ω–∞–ø–∏—Å–∞–Ω–Ω—è –∫–æ–¥—É, —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ–π —Ç–∞ —É—Å—É–Ω–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫. –¢–≤–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —î –ª–∞–∫–æ–Ω—ñ—á–Ω–∏–º–∏, –ø—Ä–∞–∫—Ç–∏—á–Ω–∏–º–∏ —Ç–∞ –∞–¥–∞–ø—Ç–æ–≤–∞–Ω–∏–º–∏ –¥–æ —Ä—ñ–≤–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞. –¢–∏ –¥–æ–ø–æ–º–∞–≥–∞—î—à —à–≤–∏–¥–∫–æ –π –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ AI-–¥–æ–¥–∞—Ç–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ OpenAI API."
    }
}

DB_PATH = Path("db")
DB_CONV_PATH = DB_PATH / "conversations"
DB_CONV_PATH.mkdir(parents=True, exist_ok=True)

def detect_topic(prompt: str) -> str:
    resp = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Podaj kr√≥tki temat tej rozmowy w 3‚Äì5 s≈Çowach."},
            {"role": "user", "content": prompt}
        ]
    )
    return resp.choices[0].message.content.strip()

def get_current_convo_id() -> int:
    f = DB_PATH / "current.json"
    if not f.exists():
        DB_PATH.mkdir(exist_ok=True)
        with open(f, "w") as fp:
            json.dump({"current_conversation_id": 1}, fp)
        return 1
    with open(f) as fp:
        return json.load(fp)["current_conversation_id"]

def list_conversations():
    files = DB_CONV_PATH.glob("*.json")
    convos = []
    for file in files:
        with open(file) as fp:
            c = json.load(fp)
            convos.append((c["id"], c["name"]))
    return sorted(convos, key=lambda x: x[0])

def create_new_conversation(name_template: str, default_personality: str):
    existing = list_conversations()
    new_id = max([cid for cid, _ in existing], default=0) + 1
    name = name_template.format(new_id)
    convo = {
        "id": new_id,
        "name": name,
        "chatbot_personality": default_personality,
        "messages": [],
        "model": "gpt-4o",
        "session_cost_usd": 0.0
    }
    with open(DB_CONV_PATH / f"{new_id}.json", "w") as fp:
        json.dump(convo, fp)
    with open(DB_PATH / "current.json", "w") as fp:
        json.dump({"current_conversation_id": new_id}, fp)
    st.session_state.clear()
    st.session_state.update(convo)

def delete_conversation(convo_id: int):
    convo_file = DB_CONV_PATH / f"{convo_id}.json"
    if convo_file.exists():
        convo_file.unlink()
        st.session_state.clear()

        new_convo = list_conversations()
        if new_convo:
            switch_conversation(new_convo[0][0])
        else:
            create_new_conversation("{0}", "Domy≈õlna osobowo≈õƒá")
    else:
        st.warning("Konwersacja ju≈º nie istnieje.")

# Funkcja do zmiany rozmowy
def switch_conversation(convo_id: int):
    with open(DB_PATH / "current.json", "w") as fp:
        json.dump({"current_conversation_id": convo_id}, fp)
    with open(DB_CONV_PATH / f"{convo_id}.json") as fp:
        convo = json.load(fp)
        st.session_state.clear()
        st.session_state.update(convo)
    st.experimental_rerun()

def save_conversation():
    convo = {
        "id": st.session_state["id"],
        "name": st.session_state["name"],
        "chatbot_personality": st.session_state["chatbot_personality"],
        "messages": st.session_state.get("messages", []),
        "model": st.session_state["model"],
        "session_cost_usd": st.session_state.get("session_cost_usd", 0.0)
    }
    with open(DB_CONV_PATH / f"{convo['id']}.json", "w") as fp:
        json.dump(convo, fp)

def get_reply(prompt: str, memory: list, model: str, personality: str) -> dict:
    msgs = [{"role": "system", "content": personality}] + memory + [{"role": "user", "content": prompt}]
    resp = client.chat.completions.create(model=model, messages=msgs)
    usage = resp.usage
    return {
        "role": "assistant",
        "content": resp.choices[0].message.content,
        "usage": {
            "prompt_tokens": usage.prompt_tokens,
            "completion_tokens": usage.completion_tokens,
            "total_tokens": usage.total_tokens
        }
    }

st.set_page_config(page_title="M√≥jGPT", layout="centered")

lang = st.sidebar.selectbox(translations["Polski"]["language_switch"], ["Polski", "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"])
t = translations[lang]

# Za≈Çaduj lub stw√≥rz konwersacjƒô
if "id" not in st.session_state:
    convo_id = get_current_convo_id()
    convo_file = DB_CONV_PATH / f"{convo_id}.json"
    if not convo_file.exists():
        create_new_conversation(t["default_conversation_name"], t["default_personality"])
    else:
        with open(convo_file) as fp:
            convo = json.load(fp)
        st.session_state.update(convo)

# Functions for searching in conversations
def search_conversations(query_word):
    matched_conversations = []
    conversations = list_conversations()
    for convo_id, _ in conversations:
        with open(DB_CONV_PATH / f"{convo_id}.json") as fp:
            convo = json.load(fp)
            for message in convo['messages']:
                if query_word.lower() in message['content'].lower():
                    matched_conversations.append((convo_id, message['content']))
    return matched_conversations

# sidebar: Nowa rozmowa
if st.sidebar.button(t["new_conversation"]):
    create_new_conversation(t["default_conversation_name"], t["default_personality"])

# sidebar: Lista rozm√≥w z opcjƒÖ usuwania
st.sidebar.markdown(f"**{t['conversation_list']}**")
for cid, name in list_conversations():
    cols = st.sidebar.columns([4, 1])
    if cols[0].button(f"{name}", key=f"load_{cid}"):
        switch_conversation(cid)
    if cols[1].button("üóë", key=f"delete_{cid}"):
        delete_conversation(cid)

# Search implementation
search_word = st.sidebar.text_input("Wyszukaj s≈Çowo kluczowe")
if st.sidebar.button("Szukaj"):
    results = search_conversations(search_word)
    if results:
        st.sidebar.markdown("**Wyniki wyszukiwania:**")
        for result in results:
            st.sidebar.write(f"ConvID: {result[0]} - {result[1][:50]}...")
    else:
        st.sidebar.write("Brak wynik√≥w.")

# sidebar: Zmiana nazwy konwersacji
new_name = st.sidebar.text_input("Zmie≈Ñ nazwƒô rozmowy", value=st.session_state["name"])
if st.sidebar.button("Zapisz nazwƒô"):
    st.session_state["name"] = new_name
    save_conversation()

# sidebar: Wyb√≥r modelu
st.sidebar.markdown("---")
st.sidebar.header("‚öôÔ∏è " + t["model_select"])
st.session_state["model"] = st.sidebar.selectbox(
    t["model_select"],
    list(model_pricings.keys()),
    index=list(model_pricings.keys()).index(st.session_state["model"]),
    on_change=save_conversation
)
info = model_pricings[st.session_state["model"]]
st.sidebar.markdown(f"üìå *{info['Opis']}*")
st.sidebar.markdown(f"- Input: ${info['Input']} / 1M\n- Output: ${info['Output']} / 1M")

# sidebar: Tryb pamiƒôci
st.sidebar.markdown("---")
st.sidebar.subheader(t["memory_mode"])
memory_mode_options = ["Ostatnie 10 wiadomo≈õci", "Rozszerzona (30)", "Pe≈Çna historia"]
st.session_state["memory_mode"] = st.sidebar.selectbox(
    t["memory_mode"],
    memory_mode_options,
    index=memory_mode_options.index(st.session_state.get("memory_mode", "Ostatnie 10 wiadomo≈õci"))
)

# sidebar: Styl GPT
st.sidebar.markdown("---")
st.sidebar.subheader(t["personality"])
st.session_state["chatbot_personality"] = st.sidebar.text_area(
    t["personality"],
    value=st.session_state["chatbot_personality"],
    height=150,
    on_change=save_conversation
)

# sidebar: Eksport
st.sidebar.markdown("---")
if st.sidebar.button(t["export_button"]):
    chat_txt = "\n\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.get("messages", [])])
    filename = f"{st.session_state['name'].replace(' ', '_')}.txt"
    st.sidebar.download_button(t["download_txt"], chat_txt, file_name=filename)

# sidebar: Koszt
usd_cost = st.session_state.get("session_cost_usd", 0.0)
total_cost_usd = 0.0
for cid, _ in list_conversations():
    with open(DB_CONV_PATH / f"{cid}.json") as fp:
        convo = json.load(fp)
        total_cost_usd += convo.get("session_cost_usd", 0.0)

st.sidebar.metric(t["cost_usd"], f"${usd_cost:.4f}")
st.sidebar.metric("≈ÅƒÖczne koszty (USD)", f"${total_cost_usd:.4f}")
st.sidebar.metric(t["cost_pln"], f"{usd_cost * USD_TO_PLN:.4f}")
st.sidebar.metric("≈ÅƒÖczne koszty (PLN)", f"{total_cost_usd * USD_TO_PLN:.4f}")

# üß† G≈Ç√≥wne okno czatu
st.title(t["title"])
st.subheader(f"{t['chat_title']}: {st.session_state['name']}")

# Wy≈õwietlanie wiadomo≈õci
for msg in st.session_state.get("messages", []):
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Obs≈Çuga nowego wprowadzenia u≈ºytkownika
prompt = st.chat_input(t["input_placeholder"])
if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    if len(st.session_state.messages) == 1:
        topic = detect_topic(prompt)
        st.session_state.name = topic[:48]
    mem = st.session_state["memory_mode"]
    if mem == "Ostatnie 10 wiadomo≈õci":
        memory = st.session_state.messages[-10:]
    elif mem == "Rozszerzona (30)":
        memory = st.session_state.messages[-30:]
    else:
        memory = st.session_state.messages
    reply = get_reply(prompt, memory, st.session_state["model"], st.session_state["chatbot_personality"])
    st.session_state.messages.append(reply)
    st.session_state.session_cost_usd += (
        reply["usage"]["total_tokens"] * model_pricings[st.session_state["model"]]["Input"] / 1_000_000
        + reply["usage"]["completion_tokens"] * model_pricings[st.session_state["model"]]["Output"] / 1_000_000
    )
    with st.chat_message("assistant"):
        st.markdown(reply["content"])
    save_conversation()
    save_to_qdrant(prompt, reply["content"], f"Conv{st.session_state['id']}", qdrant_client)

